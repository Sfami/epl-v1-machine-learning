{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Loading Imports","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:37:30.175485Z","iopub.execute_input":"2022-06-16T20:37:30.176035Z","iopub.status.idle":"2022-06-16T20:37:30.870421Z","shell.execute_reply.started":"2022-06-16T20:37:30.175982Z","shell.execute_reply":"2022-06-16T20:37:30.869429Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.428918Z","iopub.execute_input":"2022-06-27T23:24:21.429287Z","iopub.status.idle":"2022-06-27T23:24:21.435276Z","shell.execute_reply.started":"2022-06-27T23:24:21.429257Z","shell.execute_reply":"2022-06-27T23:24:21.434433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Reading Data","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"../input/englishpremiership/test/test/2021-2022.csv\")\n\n_0 = pd.read_csv(\"../input/englishpremiership/train/train/2020-2021.csv\")\n_1 = pd.read_csv(\"../input/englishpremiership/train/train/2019-2020.csv\")\n_2 = pd.read_csv(\"../input/englishpremiership/train/train/2018-2019.csv\")\n_3 = pd.read_csv(\"../input/englishpremiership/train/train/2017-2018.csv\")\n_4 = pd.read_csv(\"../input/englishpremiership/train/train/2016-2017.csv\")\n_5 = pd.read_csv(\"../input/englishpremiership/train/train/2015-2016.csv\")\n\n_6 = pd.read_csv(\"../input/englishpremiership/train/train/2014-2015.csv\")\ntrain = pd.concat([_0,_1,_2,_3,_4,_5,_6])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.439933Z","iopub.execute_input":"2022-06-27T23:24:21.440722Z","iopub.status.idle":"2022-06-27T23:24:21.538376Z","shell.execute_reply.started":"2022-06-27T23:24:21.440688Z","shell.execute_reply":"2022-06-27T23:24:21.537612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FEATURES = ['Time', 'HomeTeam', 'AwayTeam', 'FTR','MaxH' ,'MaxD' ,'MaxA' ,'AvgH' ,'AvgD' ,'AvgA']","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.539703Z","iopub.execute_input":"2022-06-27T23:24:21.540038Z","iopub.status.idle":"2022-06-27T23:24:21.544868Z","shell.execute_reply.started":"2022-06-27T23:24:21.540009Z","shell.execute_reply":"2022-06-27T23:24:21.543750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## a) Train Data","metadata":{}},{"cell_type":"code","source":"test = test[FEATURES]\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.546077Z","iopub.execute_input":"2022-06-27T23:24:21.546426Z","iopub.status.idle":"2022-06-27T23:24:21.577366Z","shell.execute_reply.started":"2022-06-27T23:24:21.546390Z","shell.execute_reply":"2022-06-27T23:24:21.576362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## b) Test Data","metadata":{}},{"cell_type":"code","source":"test = test[FEATURES]\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.579707Z","iopub.execute_input":"2022-06-27T23:24:21.580241Z","iopub.status.idle":"2022-06-27T23:24:21.598116Z","shell.execute_reply.started":"2022-06-27T23:24:21.580196Z","shell.execute_reply":"2022-06-27T23:24:21.597514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.599210Z","iopub.execute_input":"2022-06-27T23:24:21.599668Z","iopub.status.idle":"2022-06-27T23:24:21.604005Z","shell.execute_reply.started":"2022-06-27T23:24:21.599638Z","shell.execute_reply":"2022-06-27T23:24:21.603350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## a) Categorical Variables","metadata":{}},{"cell_type":"code","source":"# Get list of categorical variables\ns = (train[FEATURES].dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.605149Z","iopub.execute_input":"2022-06-27T23:24:21.605490Z","iopub.status.idle":"2022-06-27T23:24:21.621315Z","shell.execute_reply.started":"2022-06-27T23:24:21.605465Z","shell.execute_reply":"2022-06-27T23:24:21.620427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Make copy to avoid changing original data \nlabel_train = train[FEATURES].copy()\nlabel_test = test[FEATURES].copy()\n\n# Apply ordinal encoder to each column with categorical data\nordinal_encoder = OrdinalEncoder()\nlabel_train[object_cols] = ordinal_encoder.fit_transform(label_train[object_cols])\nlabel_test[object_cols] = ordinal_encoder.fit_transform(label_test[object_cols])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.622256Z","iopub.execute_input":"2022-06-27T23:24:21.622595Z","iopub.status.idle":"2022-06-27T23:24:21.640219Z","shell.execute_reply.started":"2022-06-27T23:24:21.622568Z","shell.execute_reply":"2022-06-27T23:24:21.639334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## b) Missing Values","metadata":{}},{"cell_type":"markdown","source":"i. Here we calculate the number of missing values.","metadata":{}},{"cell_type":"code","source":"# Shape of training data (num_rows, num_columns)\nprint(label_train.shape)\n\n# Number of missing values in each column of training data\nmissing_val_count_by_column = (label_train.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.641329Z","iopub.execute_input":"2022-06-27T23:24:21.641790Z","iopub.status.idle":"2022-06-27T23:24:21.649588Z","shell.execute_reply.started":"2022-06-27T23:24:21.641757Z","shell.execute_reply":"2022-06-27T23:24:21.648709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(label_test.shape)\n\n# Number of missing values in each column of training data\nmissing_val_count_by_column = (label_test.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.677885Z","iopub.execute_input":"2022-06-27T23:24:21.678269Z","iopub.status.idle":"2022-06-27T23:24:21.685609Z","shell.execute_reply.started":"2022-06-27T23:24:21.678238Z","shell.execute_reply":"2022-06-27T23:24:21.684892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputation\nmy_imputer = SimpleImputer()\nimputed_train = pd.DataFrame(my_imputer.fit_transform(label_train))\nimputed_test = pd.DataFrame(my_imputer.transform(label_test))\n\n# Imputation removed column names; put them back\nimputed_train.columns = label_train.columns\nimputed_test.columns = label_test.columns","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.686955Z","iopub.execute_input":"2022-06-27T23:24:21.687539Z","iopub.status.idle":"2022-06-27T23:24:21.706972Z","shell.execute_reply.started":"2022-06-27T23:24:21.687485Z","shell.execute_reply":"2022-06-27T23:24:21.705979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(imputed_test.shape)\n\n# Number of missing values in each column of training data\nmissing_val_count_by_column = (imputed_test.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.710468Z","iopub.execute_input":"2022-06-27T23:24:21.711057Z","iopub.status.idle":"2022-06-27T23:24:21.717057Z","shell.execute_reply.started":"2022-06-27T23:24:21.711026Z","shell.execute_reply":"2022-06-27T23:24:21.716479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(imputed_train.shape)\n\n# Number of missing values in each column of training data\nmissing_val_count_by_column = (imputed_train.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.717984Z","iopub.execute_input":"2022-06-27T23:24:21.718762Z","iopub.status.idle":"2022-06-27T23:24:21.729956Z","shell.execute_reply.started":"2022-06-27T23:24:21.718729Z","shell.execute_reply":"2022-06-27T23:24:21.729035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_X_full = imputed_train.drop(\"FTR\", axis=1)\ntest_X_full = imputed_test.drop(\"FTR\", axis=1)\n\n# train_X_full = imputed_train\n# test_X_full = imputed_test\n\ncategorical_cols = [cname for cname in train_X_full.columns if train_X_full[cname].nunique() < 10 and \n                        train_X_full[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in train_X_full.columns if train_X_full[cname].dtype in ['int64', 'float64']]\n\n# Keep selected columns only\nmy_cols = categorical_cols + numerical_cols\n\n# train_X = train_X_full[my_cols].copy()\n# test_X = test_X_full[my_cols].copy()\n\ntrain_X = train_X_full.copy()\ntest_X = test_X_full.copy()\n\ntrain_y = label_train.FTR\ntest_y = label_test.FTR","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.731428Z","iopub.execute_input":"2022-06-27T23:24:21.731877Z","iopub.status.idle":"2022-06-27T23:24:21.742848Z","shell.execute_reply.started":"2022-06-27T23:24:21.731849Z","shell.execute_reply":"2022-06-27T23:24:21.741722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.concat([train_X, test_X])\ny = pd.concat([train_y, test_y])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.744029Z","iopub.execute_input":"2022-06-27T23:24:21.744598Z","iopub.status.idle":"2022-06-27T23:24:21.751031Z","shell.execute_reply.started":"2022-06-27T23:24:21.744565Z","shell.execute_reply":"2022-06-27T23:24:21.750036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\n\n# Number of missing values in each column of training data\nmissing_val_count_by_column = (X.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.752135Z","iopub.execute_input":"2022-06-27T23:24:21.752598Z","iopub.status.idle":"2022-06-27T23:24:21.763583Z","shell.execute_reply.started":"2022-06-27T23:24:21.752567Z","shell.execute_reply":"2022-06-27T23:24:21.762809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y.shape)\n\n# Number of missing values in each column of training data\nmissing_val_count_by_column = (y.isnull().sum())\nprint(missing_val_count_by_column)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.764690Z","iopub.execute_input":"2022-06-27T23:24:21.765320Z","iopub.status.idle":"2022-06-27T23:24:21.772484Z","shell.execute_reply.started":"2022-06-27T23:24:21.765290Z","shell.execute_reply":"2022-06-27T23:24:21.771561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.773749Z","iopub.execute_input":"2022-06-27T23:24:21.774221Z","iopub.status.idle":"2022-06-27T23:24:21.790049Z","shell.execute_reply.started":"2022-06-27T23:24:21.774182Z","shell.execute_reply":"2022-06-27T23:24:21.789096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Pipeline","metadata":{}},{"cell_type":"code","source":"# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.791656Z","iopub.execute_input":"2022-06-27T23:24:21.792158Z","iopub.status.idle":"2022-06-27T23:24:21.798700Z","shell.execute_reply.started":"2022-06-27T23:24:21.792117Z","shell.execute_reply":"2022-06-27T23:24:21.797868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Models","metadata":{}},{"cell_type":"code","source":"train_y = train_y.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.800713Z","iopub.execute_input":"2022-06-27T23:24:21.801251Z","iopub.status.idle":"2022-06-27T23:24:21.809495Z","shell.execute_reply.started":"2022-06-27T23:24:21.801220Z","shell.execute_reply":"2022-06-27T23:24:21.808865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## a) Base Model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nbasic_model = RandomForestRegressor(random_state=0)\n\n# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', basic_model)\n                             ])\n\n# Preprocessing of training data, fit model \nmy_pipeline.fit(train_X, train_y)\n\n# Preprocessing of validation data, get predictions\nbase_preds = my_pipeline.predict(test_X)\n\n# Evaluate the model\nbase_score = mean_absolute_error(test_y, base_preds)\nprint('MAE:', base_score)\n# print(base_preds)\n# print(test_y)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:21.811586Z","iopub.execute_input":"2022-06-27T23:24:21.812185Z","iopub.status.idle":"2022-06-27T23:24:22.428876Z","shell.execute_reply.started":"2022-06-27T23:24:21.812156Z","shell.execute_reply":"2022-06-27T23:24:22.427853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## b) Random Forest Regressor Model","metadata":{}},{"cell_type":"code","source":"rf_model = RandomForestRegressor(n_estimators=100, random_state=0)\n\n# Bundle preprocessing and modeling code in a pipeline\nrf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', rf_model)\n                             ])\n\n# Preprocessing of training data, fit model \nrf_pipeline.fit(train_X, train_y)\n\n# Preprocessing of validation data, get predictions\nrf_preds = rf_pipeline.predict(test_X)\n\n# Evaluate the model\nrf_score = mean_absolute_error(test_y, rf_preds)\nprint('MAE:', rf_score)\nprint(rf_preds)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:22.430347Z","iopub.execute_input":"2022-06-27T23:24:22.430838Z","iopub.status.idle":"2022-06-27T23:24:23.049943Z","shell.execute_reply.started":"2022-06-27T23:24:22.430807Z","shell.execute_reply":"2022-06-27T23:24:23.048997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## c) Random Forest Classifier Model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n\nrfc_model = RandomForestClassifier(n_estimators=100)\n\nrfc_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', rfc_model)\n                             ])\n\n# Preprocessing of training data, fit model \nrfc_pipeline.fit(train_X, train_y)\n\n# Preprocessing of validation data, get predictions\nrfc_preds = rfc_pipeline.predict(test_X)\n\n# Evaluate the model\nrfc_score = mean_absolute_error(test_y, rfc_preds)\nprint('MAE:', rfc_score)\n# print(rfc_preds)\n# print(test_y)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:25:10.245809Z","iopub.execute_input":"2022-06-27T23:25:10.246193Z","iopub.status.idle":"2022-06-27T23:25:10.692539Z","shell.execute_reply.started":"2022-06-27T23:25:10.246163Z","shell.execute_reply":"2022-06-27T23:25:10.691587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## d) XGBoost Model","metadata":{}},{"cell_type":"code","source":"xgb_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)\n\n# Bundle preprocessing and modeling code in a pipeline\nxgb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', xgb_model)\n                             ])\n\n# Preprocessing of training data, fit model \nxgb_pipeline.fit(train_X, train_y)\n\n# Preprocessing of validation data, get predictions\nxgb_preds = xgb_pipeline.predict(test_X)\n\n# Evaluate the model\nxgb_score = mean_absolute_error(test_y, xgb_preds)\nprint('MAE:', xgb_score)\nprint(xgb_preds)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:25:14.139223Z","iopub.execute_input":"2022-06-27T23:25:14.139591Z","iopub.status.idle":"2022-06-27T23:25:14.158901Z","shell.execute_reply.started":"2022-06-27T23:25:14.139562Z","shell.execute_reply":"2022-06-27T23:25:14.157670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Model Validation","metadata":{}},{"cell_type":"code","source":"y = y.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.074638Z","iopub.status.idle":"2022-06-27T23:24:23.075109Z","shell.execute_reply.started":"2022-06-27T23:24:23.074949Z","shell.execute_reply":"2022-06-27T23:24:23.074967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(my_pipeline, X, y,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\n\nprint(\"MAE scores:\\n\", scores)\nprint()\n\nprint(\"Average MAE score (across experiments):\")\nprint(scores.mean())","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.076103Z","iopub.status.idle":"2022-06-27T23:24:23.076468Z","shell.execute_reply.started":"2022-06-27T23:24:23.076306Z","shell.execute_reply":"2022-06-27T23:24:23.076324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(rf_pipeline, X, y,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\n\nprint(\"MAE scores:\\n\", scores)\nprint()\n\nprint(\"Average MAE score (across experiments):\")\nprint(scores.mean())\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.077598Z","iopub.status.idle":"2022-06-27T23:24:23.077955Z","shell.execute_reply.started":"2022-06-27T23:24:23.077787Z","shell.execute_reply":"2022-06-27T23:24:23.077805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(rfc_pipeline, X, y,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\n\nprint(\"MAE scores:\\n\", scores)\nprint()\n\nprint(\"Average MAE score (across experiments):\")\nprint(scores.mean())\n\nprint()\n\ncv_scores = cross_val_score(rfc_pipeline, X, y, \n                            cv=5,\n                            scoring='accuracy')\n\nprint(\"Cross-validation accuracy: %f\" % cv_scores.mean())","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.079223Z","iopub.status.idle":"2022-06-27T23:24:23.080013Z","shell.execute_reply.started":"2022-06-27T23:24:23.079835Z","shell.execute_reply":"2022-06-27T23:24:23.079855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(xgb_pipeline, X, y,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\n\nprint(\"MAE scores:\\n\", scores)\nprint()\n\nprint(\"Average MAE score (across experiments):\")\nprint(scores.mean())","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.080995Z","iopub.status.idle":"2022-06-27T23:24:23.081620Z","shell.execute_reply.started":"2022-06-27T23:24:23.081390Z","shell.execute_reply":"2022-06-27T23:24:23.081413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Improvements (Feature Engineering)","metadata":{}},{"cell_type":"markdown","source":"## a) Mutual Information","metadata":{}},{"cell_type":"code","source":"def make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\ndiscrete_features = X.dtypes == int\nmi_scores = make_mi_scores(X, y, discrete_features)\nmi_scores # show a few features with their MI scores","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.082798Z","iopub.status.idle":"2022-06-27T23:24:23.083158Z","shell.execute_reply.started":"2022-06-27T23:24:23.082999Z","shell.execute_reply":"2022-06-27T23:24:23.083016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n\n\nplt.figure(dpi=100, figsize=(8, 5))\nplot_mi_scores(mi_scores)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.084723Z","iopub.status.idle":"2022-06-27T23:24:23.085082Z","shell.execute_reply.started":"2022-06-27T23:24:23.084922Z","shell.execute_reply":"2022-06-27T23:24:23.084939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.relplot(x=\"FTAG\", y=\"FTR\", data = pd.concat([train,test]));","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.086163Z","iopub.status.idle":"2022-06-27T23:24:23.086491Z","shell.execute_reply.started":"2022-06-27T23:24:23.086333Z","shell.execute_reply":"2022-06-27T23:24:23.086349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.087306Z","iopub.status.idle":"2022-06-27T23:24:23.087669Z","shell.execute_reply.started":"2022-06-27T23:24:23.087477Z","shell.execute_reply":"2022-06-27T23:24:23.087492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create cluster feature\nkmeans = KMeans(n_clusters=6)\nX[\"Cluster\"] = kmeans.fit_predict(X)\nX[\"Cluster\"] = X[\"Cluster\"].astype(\"category\")\n\nX.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.088531Z","iopub.status.idle":"2022-06-27T23:24:23.088859Z","shell.execute_reply.started":"2022-06-27T23:24:23.088706Z","shell.execute_reply":"2022-06-27T23:24:23.088723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.relplot(\n    y=\"HomeTeam\", x=\"MaxD\", hue=\"Cluster\", data=X, height=6,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.089667Z","iopub.status.idle":"2022-06-27T23:24:23.089986Z","shell.execute_reply.started":"2022-06-27T23:24:23.089841Z","shell.execute_reply":"2022-06-27T23:24:23.089856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X[\"MedHouseVal\"] = df[\"MedHouseVal\"]\nsns.catplot(x=\"Time\", y=\"Cluster\", data=X, kind=\"boxen\", height=6)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.091182Z","iopub.status.idle":"2022-06-27T23:24:23.091540Z","shell.execute_reply.started":"2022-06-27T23:24:23.091344Z","shell.execute_reply":"2022-06-27T23:24:23.091360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scaled = (X[numerical_cols] - X[numerical_cols].mean(axis=0)) / X[numerical_cols].std(axis=0)\nX_scaled.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.092643Z","iopub.status.idle":"2022-06-27T23:24:23.092962Z","shell.execute_reply.started":"2022-06-27T23:24:23.092816Z","shell.execute_reply":"2022-06-27T23:24:23.092832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of training data (num_rows, num_columns)\nprint(X_scaled.shape)\n\n# Number of missing values in each column of training data\nmissing_val_count_by_column = (X_scaled.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.093972Z","iopub.status.idle":"2022-06-27T23:24:23.094291Z","shell.execute_reply.started":"2022-06-27T23:24:23.094141Z","shell.execute_reply":"2022-06-27T23:24:23.094156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create principal components\npca = PCA()\nX_pca = pca.fit_transform(X_scaled)\n\n# Convert to dataframe\ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_pca.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.095437Z","iopub.status.idle":"2022-06-27T23:24:23.095810Z","shell.execute_reply.started":"2022-06-27T23:24:23.095649Z","shell.execute_reply":"2022-06-27T23:24:23.095667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loadings = pd.DataFrame(\n    pca.components_.T,  # transpose the matrix of loadings\n    columns=component_names,  # so the columns are the principal components\n    index=X_scaled.columns,  # and the rows are the original features\n)\nloadings","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.099139Z","iopub.status.idle":"2022-06-27T23:24:23.099546Z","shell.execute_reply.started":"2022-06-27T23:24:23.099350Z","shell.execute_reply":"2022-06-27T23:24:23.099369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\n\n\ndef plot_variance(pca, width=8, dpi=100):\n    # Create figure\n    fig, axs = plt.subplots(1, 2)\n    n = pca.n_components_\n    grid = np.arange(1, n + 1)\n    # Explained variance\n    evr = pca.explained_variance_ratio_\n    axs[0].bar(grid, evr)\n    axs[0].set(\n        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n    )\n    # Cumulative Variance\n    cv = np.cumsum(evr)\n    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n    axs[1].set(\n        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n    )\n    # Set up figure\n    fig.set(figwidth=8, dpi=100)\n    return axs\n\ndef make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.100884Z","iopub.status.idle":"2022-06-27T23:24:23.101238Z","shell.execute_reply.started":"2022-06-27T23:24:23.101078Z","shell.execute_reply":"2022-06-27T23:24:23.101096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at explained variance\nplot_variance(pca)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.102627Z","iopub.status.idle":"2022-06-27T23:24:23.102973Z","shell.execute_reply.started":"2022-06-27T23:24:23.102816Z","shell.execute_reply":"2022-06-27T23:24:23.102833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi_scores = make_mi_scores(X_pca, y.fillna(0), discrete_features=False)\nmi_scores","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.104558Z","iopub.status.idle":"2022-06-27T23:24:23.105109Z","shell.execute_reply.started":"2022-06-27T23:24:23.104933Z","shell.execute_reply":"2022-06-27T23:24:23.104953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since there is no preprocessing, we don't need a pipeline (used anyway as best practice!)\n\ntrain_X_pca, test_X_pca, train_y, test_y = train_test_split(X_pca, y, train_size=0.8, test_size=0.2, random_state=0)\n\nrfc_pca_model = RandomForestClassifier(n_estimators=100)\n\n# rfc_pca_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n#                               ('model', rfc_pca_model)\n#                              ])\n\n# Preprocessing of training data, fit model \nrfc_pca_model.fit(train_X_pca, train_y)\n\n# Preprocessing of validation data, get predictions\nrfc_pca_preds = rfc_pca_model.predict(test_X_pca)\n\n# Evaluate the model\nrfc_pca_score = mean_absolute_error(test_y, rfc_pca_preds)\nprint('MAE:', rfc_pca_score)\nprint()\nprint('Predictions\\n', rfc_pca_preds)\nprint()\nprint('Test set\\n', test_y.values)\n\n# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(rfc_pca_model, X, y,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\n\nprint(\"MAE scores:\\n\", scores)\nprint()\n\nprint(\"Average MAE score (across experiments):\")\nprint(scores.mean())\nprint()\n\ncv_scores = cross_val_score(rfc_pca_model, X, y, \n                            cv=5,\n                            scoring='accuracy')\n\nprint(\"Cross-validation accuracy: %f\" % cv_scores.mean())","metadata":{"execution":{"iopub.status.busy":"2022-06-27T23:24:23.106018Z","iopub.status.idle":"2022-06-27T23:24:23.106366Z","shell.execute_reply.started":"2022-06-27T23:24:23.106206Z","shell.execute_reply":"2022-06-27T23:24:23.106224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Position they finished last year.\n2. Division in which they were playing last year.\n3. Parse Date and Time.\n4. Total goals scored last year.\n5. Total goals conceded last year.\n6. Number of cleansheets.\n7. Number of top 5 goal scorers in team.","metadata":{}}]}